<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://come7true.github.io</id>
    <title>cometrue的博客</title>
    <updated>2021-07-27T15:54:46.505Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://come7true.github.io"/>
    <link rel="self" href="https://come7true.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://come7true.github.io/images/avatar.png</logo>
    <icon>https://come7true.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, cometrue的博客</rights>
    <entry>
        <title type="html"><![CDATA[Kafka消息丢失和重复消费-小记]]></title>
        <id>https://come7true.github.io/post/kafka-questions/</id>
        <link href="https://come7true.github.io/post/kafka-questions/">
        </link>
        <updated>2021-07-27T15:12:40.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-消息丢失">一、消息丢失</h3>
<p>1、生产者丢失消息</p>
<p>原因：生产者消息发送到broker的过程中由于网络原因或其它异常丢失</p>
<p>解决方案：ack机制，设置acks</p>
<p>acks=0，消息发送后不管是否到达broker，这种情况最容易产生消息丢失，通常在大流量日志记录场景下使用</p>
<p>acks=1，消息发送后只要leader分区写入完成即认为完成，此时如果follower还未同步完成leader就挂掉，重新推选leader后会发生消息丢失</p>
<p>acks=-1/all，消息发送后必须等到所有分区都写入完成才认为发送完成，这样只要有一个分区存活就能保证数据不丢失，但是效率最低，一般在金融应用领域使用</p>
<p>2、消费者丢失消息</p>
<p>原因：kafka配置自动提交offset值，消费者还未消费完成就挂掉，rebalance之后从新的offset开始消费，导致消息丢失</p>
<p>解决方案：配置kafka由手动提交offset</p>
<h3 id="二-重复消费">二、重复消费</h3>
<p>1、生产者重复生产消息</p>
<p>原因：生产者消息发送后broker收到消息，但是生产者未收到broker的响应，触发重试机制导致消息重复</p>
<p>解决方案：配置enable.idempotence=true开启broker接收消息的幂等性</p>
<p>原理：在初始化生产者时分配一个唯一的pid，每次提交都会递增一个sequence number（从0开始），发送消息时会携带这两个信息，broker记录值并在每次收到消息时比对，如果相同则拒绝接收</p>
<p>2、消费者重复消费</p>
<p>原因：消费者消费完成后手动提交offset，此时因为异常未能提交成功，之后又从原来的offset开始消费</p>
<p>解决方案：核心思想还是保证幂等性。通过其它中间价配合解决，比如在消费开始之前先将分区和offset值作为唯一key写redis（最好设置过期时间），消费完成并提交offset后将key删除。这样万一消费完没有成功提交offset，再次消费前检查是否存在key，若存在则不消费并删除key进入下一次消费重复过程</p>
]]></content>
    </entry>
</feed>