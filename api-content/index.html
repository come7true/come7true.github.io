{"posts":[{"title":"Kafka消息丢失和重复消费-小记","content":"一、消息丢失 1、生产者丢失消息 原因：生产者消息发送到broker的过程中由于网络原因或其它异常丢失 解决方案：ack机制，设置acks acks=0，消息发送后不管是否到达broker，这种情况最容易产生消息丢失，通常在大流量日志记录场景下使用 acks=1，消息发送后只要leader分区写入完成即认为完成，此时如果follower还未同步完成leader就挂掉，重新推选leader后会发生消息丢失 acks=-1/all，消息发送后必须等到所有分区都写入完成才认为发送完成，这样只要有一个分区存活就能保证数据不丢失，但是效率最低，一般在金融应用领域使用 2、消费者丢失消息 原因：kafka配置自动提交offset值，消费者还未消费完成就挂掉，rebalance之后从新的offset开始消费，导致消息丢失 解决方案：配置kafka由手动提交offset 二、重复消费 1、生产者重复生产消息 原因：生产者消息发送后broker收到消息，但是生产者未收到broker的响应，触发重试机制导致消息重复 解决方案：配置enable.idempotence=true开启broker接收消息的幂等性 原理：在初始化生产者时分配一个唯一的pid，每次提交都会递增一个sequence number（从0开始），发送消息时会携带这两个信息，broker记录值并在每次收到消息时比对，如果相同则拒绝接收 2、消费者重复消费 原因：消费者消费完成后手动提交offset，此时因为异常未能提交成功，之后又从原来的offset开始消费 解决方案：核心思想还是保证幂等性。通过其它中间价配合解决，比如在消费开始之前先将分区和offset值作为唯一key写redis（最好设置过期时间），消费完成并提交offset后将key删除。这样万一消费完没有成功提交offset，再次消费前检查是否存在key，若存在则不消费并删除key进入下一次消费重复过程 ","link":"https://come7true.github.io/post/kafka-questions/"}]}